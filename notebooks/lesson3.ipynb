{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51973f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "Cannot add duplicate partition field null=truncate[1](ref(name=\"firstName\")), conflicts with 1001: firstName_trunc_1: truncate[1](3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE IF NOT EXISTS nessie.df_open_2023_lesson3 USING iceberg PARTITIONED BY (countryOfOriginCode) AS SELECT * FROM csv_open_2023 ORDER BY countryOfOriginCode;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m## ALTER PARTITIONING BASED ON TRUNCATE FIRST LETTER OF firstName\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALTER TABLE nessie.df_open_2023_lesson3 ADD PARTITION FIELD truncate(1, firstName)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m## REWRITE ALL THE DATA SO IT ALL USES UPDATED PARTITONING\u001b[39;00m\n\u001b[1;32m     49\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL nessie.system.rewrite_data_files(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_open_2023_lesson3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Cannot add duplicate partition field null=truncate[1](ref(name=\"firstName\")), conflicts with 1001: firstName_trunc_1: truncate[1](3)"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "## DEFINE SENSITIVE VARIABLES\n",
    "NESSIE_URI = \"http://nessie:19120/api/v1\"\n",
    "MINIO_ACCESS_KEY = \"admin\"\n",
    "MINIO_SECRET_KEY = \"password\"\n",
    "\n",
    "\n",
    "\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('app_name')\n",
    "  \t\t#packages\n",
    "        .set('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.1,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.3_2.12:0.67.0,software.amazon.awssdk:bundle:2.17.178,software.amazon.awssdk:url-connection-client:2.17.178')\n",
    "  \t\t#SQL Extensions\n",
    "        .set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "  \t\t#Configuring Catalog\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', NESSIE_URI)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        .set('spark.sql.catalog.nessie.warehouse', 's3a://warehouse')\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', 'http://minio:9000')\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "  \t\t#MINIO CREDENTIALS\n",
    "        .set('spark.hadoop.fs.s3a.access.key', MINIO_ACCESS_KEY)\n",
    "        .set('spark.hadoop.fs.s3a.secret.key', MINIO_SECRET_KEY)\n",
    ")\n",
    "\n",
    "## Start Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark Running\")\n",
    "\n",
    "## LOAD A CSV INTO AN SQL VIEW\n",
    "csv_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../datasets/df_open_2023.csv\")\n",
    "csv_df.createOrReplaceTempView(\"csv_open_2023\")\n",
    "\n",
    "## CREATE AN ICEBERG TABLE FROM THE SQL VIEW\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS nessie.df_open_2023_lesson3 USING iceberg PARTITIONED BY (countryOfOriginCode) AS SELECT * FROM csv_open_2023 ORDER BY countryOfOriginCode;\").show()\n",
    "\n",
    "## ALTER PARTITIONING BASED ON TRUNCATE FIRST LETTER OF firstName\n",
    "spark.sql(\"ALTER TABLE nessie.df_open_2023_lesson3 ADD PARTITION FIELD truncate(1, firstName)\").show()\n",
    "\n",
    "## REWRITE ALL THE DATA SO IT ALL USES UPDATED PARTITONING\n",
    "spark.sql(\"CALL nessie.system.rewrite_data_files('df_open_2023_lesson3')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4949a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-------------+------------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|competitorId|     competitorName|    firstName|    lastName|status|gender|countryOfOriginCode|countryOfOriginName|regionId|regionName|affiliateId|       affiliateName|age|height|weight|overallRank|overallScore|genderId|year|\n",
      "+------------+-------------------+-------------+------------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|      455113|      Harmeet Singh|      Harmeet|       Singh|   ACT|     M|                 IN|              India|      28|      Asia|      19739|        CrossFit BFG| 37|180 cm| 78 kg|      16500|       92381|      18|2023|\n",
      "|     1116202|    Himanshu Mittal|     Himanshu|      Mittal|   ACT|     M|                 IN|              India|      28|      Asia|        932|      CrossFit Edina| 35|  null|  null|      60724|      258810|      18|2023|\n",
      "|     1513429|     Harish Kannuri|       Harish|     Kannuri|   ACT|     M|                 IN|              India|      28|      Asia|       4259|Thomasville CrossFit| 29|  null|  null|      71214|      293577|       1|2023|\n",
      "|     2097777|  Hareesh Ravindran|      Hareesh|   Ravindran|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 31|179 cm| 66 kg|      81858|      326985|       1|2023|\n",
      "|     2510336|      Harsh Khaneja|        Harsh|     Khaneja|   ACT|     M|                 IN|              India|      28|      Asia|      19595|Reebok CrossFit G...| 37|  null|  null|      87058|      343228|      18|2023|\n",
      "|     2255141|    Hemanth Kommuru|      Hemanth|     Kommuru|   ACT|     M|                 IN|              India|      28|      Asia|       9191|    CrossFit Almaden| 40|186 cm|191 lb|      88714|      348475|      12|2023|\n",
      "|     1995576|  Harmanpreet Singh|  Harmanpreet|       Singh|   ACT|     M|                 IN|              India|      28|      Asia|      18301|     Plus64 CrossFit| 30|  null|  null|     113295|      426761|       1|2023|\n",
      "|     2241980|    Harish Ponnappa|       Harish|    Ponnappa|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 46|168 cm| 75 kg|     117200|      439650|       3|2023|\n",
      "|     2513338|        Hrishi Dave|       Hrishi|        Dave|   ACT|     M|                 IN|              India|      28|      Asia|       7969|CrossFit Life Per...| 31|  null|  null|     117666|      441239|       1|2023|\n",
      "|     2452209|    Husein Khambata|       Husein|    Khambata|   ACT|     M|                 IN|              India|      28|      Asia|      23585|  Tech City CrossFit| 26|  null|  null|     122359|      456795|       1|2023|\n",
      "|     1705613|  Hemanth Dharavath|      Hemanth|   Dharavath|   ACT|     M|                 IN|              India|      28|      Asia|      10183|        CrossFit 190| 30|  null|  null|     124482|      464037|       1|2023|\n",
      "|     2422962|        Harsh Patel|        Harsh|       Patel|   ACT|     M|                 IN|              India|      28|      Asia|      21228|  CrossFit Severance| 28|  null|  null|     125502|      467369|       1|2023|\n",
      "|     1499369|Hardeep Singh Sohee|Hardeep Singh|       Sohee|   ACT|     M|                 IN|              India|      28|      Asia|      16015|       CrossFit Pyro| 36| 65 in|  null|     125628|      467902|      18|2023|\n",
      "|     1763779|Harsha Katakamsethy|       Harsha|Katakamsethy|   ACT|     M|                 IN|              India|      28|      Asia|        841|  CrossFit One World| 34|  null|  null|     133057|      496066|       1|2023|\n",
      "|     1613672|   Harshad Nigudkar|      Harshad|    Nigudkar|   ACT|     M|                 IN|              India|      28|      Asia|      10324|     CrossFit Lutece| 40|173 cm| 70 kg|     133684|      498422|      12|2023|\n",
      "|     1873044| Harikrishna Prabhu|  Harikrishna|      Prabhu|   ACT|     M|                 IN|              India|      28|      Asia|      22708|       CrossFit Mend| 29|181 cm| 84 kg|     135126|      504347|       1|2023|\n",
      "|     2415014|     Harikumar Suma|    Harikumar|        Suma|   ACT|     M|                 IN|              India|      28|      Asia|      22846|       CrossFit Jena| 31| 74 in|114 kg|     147584|      547078|       1|2023|\n",
      "|     2499760|       Harsha Gedda|       Harsha|       Gedda|   ACT|     M|                 IN|              India|      28|      Asia|       1697|  CrossFit Green Bay| 31|  null|  null|     148246|      549168|       1|2023|\n",
      "|     2489137|     Hitesh Nagothu|       Hitesh|     Nagothu|   ACT|     M|                 IN|              India|      28|      Asia|       8378|        CrossFit 630| 28|  null|  null|     151857|      561421|       1|2023|\n",
      "|     2386216|       Hitesh Bahar|       Hitesh|       Bahar|   ACT|     M|                 IN|              India|      28|      Asia|      13258|    Pullman CrossFit| 30|  null|  null|     153545|      567296|       1|2023|\n",
      "+------------+-------------------+-------------+------------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.df_open_2023_lesson3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1077db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "View `default`.`top_ten` already exists. If you want to update the view definition, please use ALTER VIEW AS or CREATE OR REPLACE VIEW AS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE VIEW top_ten AS SELECT * FROM nessie.df_open_2023_lesson3 LIMIT 10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     sqlQuery \u001b[38;5;241m=\u001b[39m formatter\u001b[38;5;241m.\u001b[39mformat(sqlQuery, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: View `default`.`top_ten` already exists. If you want to update the view definition, please use ALTER VIEW AS or CREATE OR REPLACE VIEW AS"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE VIEW top_ten AS SELECT * FROM nessie.df_open_2023_lesson3 LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c090441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|competitorId|   competitorName|  firstName| lastName|status|gender|countryOfOriginCode|countryOfOriginName|regionId|regionName|affiliateId|       affiliateName|age|height|weight|overallRank|overallScore|genderId|year|\n",
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|      455113|    Harmeet Singh|    Harmeet|    Singh|   ACT|     M|                 IN|              India|      28|      Asia|      19739|        CrossFit BFG| 37|180 cm| 78 kg|      16500|       92381|      18|2023|\n",
      "|     1116202|  Himanshu Mittal|   Himanshu|   Mittal|   ACT|     M|                 IN|              India|      28|      Asia|        932|      CrossFit Edina| 35|  null|  null|      60724|      258810|      18|2023|\n",
      "|     1513429|   Harish Kannuri|     Harish|  Kannuri|   ACT|     M|                 IN|              India|      28|      Asia|       4259|Thomasville CrossFit| 29|  null|  null|      71214|      293577|       1|2023|\n",
      "|     2097777|Hareesh Ravindran|    Hareesh|Ravindran|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 31|179 cm| 66 kg|      81858|      326985|       1|2023|\n",
      "|     2510336|    Harsh Khaneja|      Harsh|  Khaneja|   ACT|     M|                 IN|              India|      28|      Asia|      19595|Reebok CrossFit G...| 37|  null|  null|      87058|      343228|      18|2023|\n",
      "|     2255141|  Hemanth Kommuru|    Hemanth|  Kommuru|   ACT|     M|                 IN|              India|      28|      Asia|       9191|    CrossFit Almaden| 40|186 cm|191 lb|      88714|      348475|      12|2023|\n",
      "|     1995576|Harmanpreet Singh|Harmanpreet|    Singh|   ACT|     M|                 IN|              India|      28|      Asia|      18301|     Plus64 CrossFit| 30|  null|  null|     113295|      426761|       1|2023|\n",
      "|     2241980|  Harish Ponnappa|     Harish| Ponnappa|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 46|168 cm| 75 kg|     117200|      439650|       3|2023|\n",
      "|     2513338|      Hrishi Dave|     Hrishi|     Dave|   ACT|     M|                 IN|              India|      28|      Asia|       7969|CrossFit Life Per...| 31|  null|  null|     117666|      441239|       1|2023|\n",
      "|     2452209|  Husein Khambata|     Husein| Khambata|   ACT|     M|                 IN|              India|      28|      Asia|      23585|  Tech City CrossFit| 26|  null|  null|     122359|      456795|       1|2023|\n",
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM top_ten\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c013d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=================================================>    (100 + 8) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS nessie.top_ten USING iceberg AS SELECT * FROM top_ten ORDER BY lastName\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09bb476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|competitorId|   competitorName|  firstName| lastName|status|gender|countryOfOriginCode|countryOfOriginName|regionId|regionName|affiliateId|       affiliateName|age|height|weight|overallRank|overallScore|genderId|year|\n",
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "|     2513338|      Hrishi Dave|     Hrishi|     Dave|   ACT|     M|                 IN|              India|      28|      Asia|       7969|CrossFit Life Per...| 31|  null|  null|     117666|      441239|       1|2023|\n",
      "|     1513429|   Harish Kannuri|     Harish|  Kannuri|   ACT|     M|                 IN|              India|      28|      Asia|       4259|Thomasville CrossFit| 29|  null|  null|      71214|      293577|       1|2023|\n",
      "|     2452209|  Husein Khambata|     Husein| Khambata|   ACT|     M|                 IN|              India|      28|      Asia|      23585|  Tech City CrossFit| 26|  null|  null|     122359|      456795|       1|2023|\n",
      "|     2510336|    Harsh Khaneja|      Harsh|  Khaneja|   ACT|     M|                 IN|              India|      28|      Asia|      19595|Reebok CrossFit G...| 37|  null|  null|      87058|      343228|      18|2023|\n",
      "|     2255141|  Hemanth Kommuru|    Hemanth|  Kommuru|   ACT|     M|                 IN|              India|      28|      Asia|       9191|    CrossFit Almaden| 40|186 cm|191 lb|      88714|      348475|      12|2023|\n",
      "|     1116202|  Himanshu Mittal|   Himanshu|   Mittal|   ACT|     M|                 IN|              India|      28|      Asia|        932|      CrossFit Edina| 35|  null|  null|      60724|      258810|      18|2023|\n",
      "|     2241980|  Harish Ponnappa|     Harish| Ponnappa|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 46|168 cm| 75 kg|     117200|      439650|       3|2023|\n",
      "|     2097777|Hareesh Ravindran|    Hareesh|Ravindran|   ACT|     M|                 IN|              India|      28|      Asia|      22847|    I Think CrossFit| 31|179 cm| 66 kg|      81858|      326985|       1|2023|\n",
      "|      455113|    Harmeet Singh|    Harmeet|    Singh|   ACT|     M|                 IN|              India|      28|      Asia|      19739|        CrossFit BFG| 37|180 cm| 78 kg|      16500|       92381|      18|2023|\n",
      "|     1995576|Harmanpreet Singh|Harmanpreet|    Singh|   ACT|     M|                 IN|              India|      28|      Asia|      18301|     Plus64 CrossFit| 30|  null|  null|     113295|      426761|       1|2023|\n",
      "+------------+-----------------+-----------+---------+------+------+-------------------+-------------------+--------+----------+-----------+--------------------+---+------+------+-----------+------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.top_ten\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
